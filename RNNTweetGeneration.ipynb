{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNNTweetGeneration.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AstroNoodles/Mini-Projects/blob/master/RNNTweetGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "XvpOnvo0MOqk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Recurrent Neural Network With Trump Generator Tweets in Keras\n",
        "\n",
        "Rnns to use:\n",
        "\n",
        "\n",
        "*   GRU\n",
        "*   LSTM\n",
        "*   AlphaDropout / Dropout - To apply to the layer\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1HWdel_WcLGD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import the libraries\n",
        "import tensorflow.keras as keras\n",
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0HDYZUegPZ4H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "csv_url = \"https://raw.githubusercontent.com/lucamusk/Atomhacks2019TrumpBot/master/TrumpTweets.csv?token=AXOm-jThREnKNDIWCp2--ddMRzO1C2VWks5cqMiXwA%3D%3D\"\n",
        "df = pd.read_csv(csv_url, header=0)\n",
        "\n",
        "tweets = df['text']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qI-l3oZIUjjo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_set_tweets = tweets[:1000]\n",
        "train_set_tweets = train_set_tweets.str.replace(\" &amp;\", \"&\")\n",
        "tweets.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TM_nq1R0SYCE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "concat_thousand_tweets = \"\"\n",
        "for i in range(1000):\n",
        "  concat_thousand_tweets += train_set_tweets[i]\n",
        "  \n",
        "vocab = sorted(set(concat_thousand_tweets))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HlMW0Nt8XodT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VwCM_F2gY8TC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}