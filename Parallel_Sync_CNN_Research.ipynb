{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parallel Sync CNN Research.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AstroNoodles/Mini-Projects/blob/master/Parallel_Sync_CNN_Research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAGvK8NCk4eZ",
        "colab_type": "text"
      },
      "source": [
        "# Parallel Synchronous Gradient Descent CNN Research\n",
        "In this notebook, I am led by graduate student Pengzhan Guo to create a synchronous CNN that can be parallelized between multiple supercomputers and is optimized by the best gradient descent networks (ADAM or RMSProp).\n",
        "\n",
        "The CNN will be trained using the CiFAR dataset which will predict images out of 10 classes and multiple trials of the experiment will be done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3OczuioYX3X",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/geifmany/cifar-vgg/blob/master/cifar10vgg.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sERWrdZJhDMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To run Keras on any GPUs on the computer, this line must be included\n",
        "# !pip3 install tensorflow-gpu\n",
        "# !pip3 install scipy\n",
        "# !pip3 install Pillow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsNj0qWzsfGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Obtain the imports for the project\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 128\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXEyw05F9nAX",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing the dataset\n",
        "This is the step where visualization and preprocessing is done in the CIFAR10 dataset that Keras gives us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09xsHmNj9k4W",
        "colab_type": "code",
        "outputId": "0eec18a1-d985-4cc1-9244-6632e6a0f501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "print(\"The shape of the training data is \" + str(x_train.shape) + \" and the shape of the labels are \" + str(y_train.shape))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the training data is (50000, 32, 32, 3) and the shape of the labels are (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDVt_PNX3DsN",
        "colab_type": "code",
        "outputId": "9969b1c5-f194-4158-841a-a98b9c371763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "source": [
        "def visualize_cifar(train_data):\n",
        "  \"\"\" Visualizes the cifar-10 dataset using matplotlib. This helps give a greater understanding\n",
        "      of the items that are in the dataset\"\"\"\n",
        "  plt.figure(figsize=(7, 7))\n",
        "  for i in range(1, 10):\n",
        "    plt.subplot(3, 3, i)\n",
        "    plt.imshow(random.choice(train_data))\n",
        "\n",
        "visualize_cifar(x_train)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGfCAYAAADlDy3rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ne0gZDAaDYWRhDymDwWAwjCz+P8/F/uUYzFD5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 504x504 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGyhmazLz6j2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_data(x_train, x_test):\n",
        "  \"\"\" Normalizes the data by dividing by subtracting the mean \n",
        "      and dividing by the standard deviation. Akin to scikit-learn's\n",
        "      StandardScaler.\"\"\"\n",
        "  mean_train, mean_test = np.mean(x_train), np.mean(x_test)\n",
        "  std_train, std_test = np.std(x_train), np.std(x_test)\n",
        "  return ((x_train - mean_train) / std_train, (x_test - mean_test) / std_test)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt9X9WIYsjV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def smooth_label(labels, epsillion):\n",
        "  \"\"\" Adds a smooth labeling to all the one-hot encoded labels to prevent overfitting\n",
        "      in the dataset: https://tinyurl.com/kerastricks\"\"\"\n",
        "  if 0 <= epsillion <= 1:\n",
        "    labels *= (1.0 - epsillion)\n",
        "    labels += (epsillion / labels.shape[1])\n",
        "  else:\n",
        "    raise Exception(\"Label smoothing factor should be between 0 and 1. Your factor is: \" + str(epsillion))\n",
        "  \n",
        "  return labels\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYkUvDWdihFI",
        "colab_type": "text"
      },
      "source": [
        "And now, we prepare the data for preprocessing!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-dyhjj--1Kq",
        "colab_type": "code",
        "outputId": "ce842174-c7bb-4a16-83eb-aa36683f4cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x_train = x_train.astype(\"float32\")\n",
        "x_test = x_test.astype(\"float32\")\n",
        "\n",
        "x_train, x_test = normalize_data(x_train, x_test)\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=NUM_CLASSES)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=NUM_CLASSES)\n",
        "\n",
        "smooth_label(y_train, 0.1)\n",
        "print(y_train[0])\n",
        "\n",
        "# Preprocessing the image dataset by artificially increasing the training data size\n",
        "# via rescaling, shifting, flipping and rotating the dataset.\n",
        "data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    samplewise_center=True,\n",
        "    rotation_range=90, \n",
        "    width_shift_range=.2, \n",
        "    height_shift_range=.2, \n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    brightness_range=(0.0, 1.0),\n",
        "    rescale=2)\n",
        "\n",
        "data_gen.fit(x_train)\n",
        "\n",
        "reg_factor = 0.005 # Regularization factor for L2 Regularization"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01       0.01       0.01       0.01       0.01       0.01\n",
            " 0.90999997 0.01       0.01       0.01      ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dAfCyApD7Ru",
        "colab_type": "text"
      },
      "source": [
        "# Building The Model\n",
        "The models were built by using a combination of methods from the Inceptionv3 model and the VGGNet models that are on Github. The layers used are given in the imports in the first code cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0JSRwcR3bKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def create_conv_net1():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  \n",
        "  # Layer 1\n",
        "  model.add(tf.keras.layers.Conv2D(32, (3, 1), kernel_initializer=\"he_normal\", input_shape=(32, 32, 3), \n",
        "                   padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Conv2D(32, (1, 3), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))  \n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  \n",
        "  model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
        "            \n",
        "  # Layer 2\n",
        "  model.add(tf.keras.layers.Conv2D(64, (3, 1), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Conv2D(64, (1, 3), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  \n",
        "  model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
        "  model.add(tf.keras.layers.Dropout(.3))          \n",
        "            \n",
        "  # Layer 3\n",
        "  model.add(tf.keras.layers.Conv2D(128, (3, 1), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Conv2D(128, (1, 3), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  \n",
        "  model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
        "            \n",
        "  # Layer 4\n",
        "  model.add(tf.keras.layers.Conv2D(256, (3, 1), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Conv2D(256, (1, 3), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
        "   \n",
        " \n",
        "  # Layer 5\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3, 1), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Conv2D(512, (1, 3), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  \n",
        "  model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
        "  model.add(tf.keras.layers.Dropout(.5)) \n",
        "  \n",
        "            \n",
        "  # Layer 6 \n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(512, kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  # model.add(tf.keras.layers.BatchNormalization())\n",
        "  \n",
        "  # Layer 7\n",
        "  model.add(tf.keras.layers.Dense(512, kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  # model.add(tf.keras.layers.BatchNormalization())\n",
        "            \n",
        "  # Layer 8 \n",
        "  model.add(tf.keras.layers.Dense(256, kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dropout(.5))\n",
        "            \n",
        "  # Layer 9\n",
        "  # model.add(GlobalAveragePooling2D())\n",
        "  model.add(tf.keras.layers.Dense(NUM_CLASSES))\n",
        "  model.add(tf.keras.layers.Activation('softmax'))\n",
        "  \n",
        "  return model\n",
        "           "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w35xI_1T8-07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_conv_net2():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  \n",
        "  # Layer 1\n",
        "  model.add(tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer=\"he_normal\", input_shape=(32, 32, 3), \n",
        "                   padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(128, (1, 3), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))  \n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "  \n",
        "  model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
        "            \n",
        "  # Layer 2\n",
        "  model.add(tf.keras.layers.Conv2D(256, (3, 1), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(256, 1, padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "            \n",
        "                       \n",
        "  model.add(tf.keras.layers.Conv2D(256, (1, 3), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "  model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
        "  model.add(tf.keras.layers.Dropout(.2))          \n",
        "            \n",
        "  # Layer 3\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3, 1), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (1, 3), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "  model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
        "            \n",
        "  # Layer 4\n",
        "  model.add(tf.keras.layers.Conv2D(1024, (3, 1), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(1024, (1, 3), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
        "   \n",
        " \n",
        "  # Layer 5\n",
        "  model.add(tf.keras.layers.Conv2D(2056, (3, 1), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(2056, (1, 3), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "  model.add(tf.keras.layers.MaxPooling2D(1, 1))\n",
        "  model.add(tf.keras.layers.Dropout(.2)) \n",
        "            \n",
        "#   Layer 6 \n",
        "#   model.add(tf.keras.layers.Flatten())\n",
        "#   model.add(tf.keras.layers.Dense(2056, kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "#   model.add(tf.keras.layers.Activation('relu'))\n",
        "#   # model.add(tf.keras.layers.BatchNormalization())\n",
        "  \n",
        "#   # Layer 7\n",
        "#   model.add(tf.keras.layers.Dense(2056, kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "#   model.add(tf.keras.layers.Activation('relu'))\n",
        "#   # model.add(tf.keras.layers.BatchNormalization())\n",
        "            \n",
        "#   # Layer 8 \n",
        "#   model.add(tf.keras.layers.Dense(1024, kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "#   model.add(tf.keras.layers.Activation('relu'))\n",
        "#   model.add(tf.keras.layers.BatchNormalization())\n",
        "#   model.add(tf.keras.layers.Dropout(.2))\n",
        "            \n",
        " # Layer 9\n",
        "  model.add(tf.keras.layers.AveragePooling2D())\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(NUM_CLASSES))\n",
        "  model.add(tf.keras.layers.Activation('softmax'))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe5SUViXSEAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_conv_net3():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  \n",
        "  # Layer 1\n",
        "  model.add(tf.keras.layers.Conv2D(128, (3, 1), kernel_initializer=\"he_normal\", input_shape=(32, 32, 3), \n",
        "                   padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Conv2D(128, (1, 3), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))  \n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  \n",
        "            \n",
        "  # Layer 2\n",
        "  model.add(tf.keras.layers.Conv2D(256, (3, 1), strides=(2,2), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (1, 3), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "          \n",
        "            \n",
        "  # Layer 3\n",
        "  model.add(tf.keras.layers.Conv2D(512, (3, 1), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(512, (1, 3), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "            \n",
        "  # Layer 4\n",
        "  model.add(tf.keras.layers.Conv2D(1024, (3, 1), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.Conv2D(1024, (1, 3), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
        "   \n",
        " \n",
        "  # Layer 5\n",
        "  model.add(tf.keras.layers.Conv2D(2056, (3, 1), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(2056, (1, 3), padding=\"same\", kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "  # model.add(tf.keras.layers.Dropout(.2)) \n",
        "            \n",
        "#   Layer 6 \n",
        "#   model.add(tf.keras.layers.Flatten())\n",
        "#   model.add(tf.keras.layers.Dense(2056, kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "#   model.add(tf.keras.layers.Activation('relu'))\n",
        "#   # model.add(tf.keras.layers.BatchNormalization())\n",
        "  \n",
        "#   # Layer 7\n",
        "#   model.add(tf.keras.layers.Dense(2056, kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "#   model.add(tf.keras.layers.Activation('relu'))\n",
        "#   # model.add(tf.keras.layers.BatchNormalization())\n",
        "            \n",
        "#   # Layer 8 \n",
        "#   model.add(tf.keras.layers.Dense(1024, kernel_regularizer=tf.keras.regularizers.l2(reg_factor)))\n",
        "#   model.add(tf.keras.layers.Activation('relu'))\n",
        "#   model.add(tf.keras.layers.BatchNormalization())\n",
        "#   model.add(tf.keras.layers.Dropout(.2))\n",
        "            \n",
        " # Layer 9\n",
        "  model.add(tf.keras.layers.AveragePooling2D())\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(NUM_CLASSES))\n",
        "  model.add(tf.keras.layers.Activation('softmax'))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3aRBjBUi12H",
        "colab_type": "text"
      },
      "source": [
        "Now, we print the models to see their summary and number of parameters in each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH1We1lv0yDL",
        "colab_type": "code",
        "outputId": "cae756f6-c07b-4319-86e8-7bf7cf3407a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model1 = create_conv_net1()\n",
        "model2 = create_conv_net2()\n",
        "model3 = create_conv_net3()\n",
        "\n",
        "model1.summary()\n",
        "print()\n",
        "model2.summary()\n",
        "print()\n",
        "model3.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_52 (Conv2D)           (None, 32, 32, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation_62 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_54 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_53 (Conv2D)           (None, 32, 32, 32)        3104      \n",
            "_________________________________________________________________\n",
            "activation_63 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_55 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 16, 16, 64)        6208      \n",
            "_________________________________________________________________\n",
            "activation_64 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_56 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_55 (Conv2D)           (None, 16, 16, 64)        12352     \n",
            "_________________________________________________________________\n",
            "activation_65 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_57 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_56 (Conv2D)           (None, 8, 8, 128)         24704     \n",
            "_________________________________________________________________\n",
            "activation_66 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_58 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_57 (Conv2D)           (None, 8, 8, 128)         49280     \n",
            "_________________________________________________________________\n",
            "activation_67 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_59 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 4, 4, 256)         98560     \n",
            "_________________________________________________________________\n",
            "activation_68 (Activation)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_60 (Batc (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 4, 4, 256)         196864    \n",
            "_________________________________________________________________\n",
            "activation_69 (Activation)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_61 (Batc (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_60 (Conv2D)           (None, 2, 2, 512)         393728    \n",
            "_________________________________________________________________\n",
            "activation_70 (Activation)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_62 (Batc (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv2d_61 (Conv2D)           (None, 2, 2, 512)         786944    \n",
            "_________________________________________________________________\n",
            "activation_71 (Activation)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_63 (Batc (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_72 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_73 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "activation_74 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_64 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_75 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 2,240,234\n",
            "Trainable params: 2,235,754\n",
            "Non-trainable params: 4,480\n",
            "_________________________________________________________________\n",
            "\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_62 (Conv2D)           (None, 32, 32, 128)       3584      \n",
            "_________________________________________________________________\n",
            "batch_normalization_65 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_76 (Activation)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           (None, 32, 32, 128)       49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_66 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_77 (Activation)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           (None, 16, 16, 256)       98560     \n",
            "_________________________________________________________________\n",
            "batch_normalization_67 (Batc (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_78 (Activation)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_65 (Conv2D)           (None, 16, 16, 256)       65792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_68 (Batc (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_79 (Activation)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_66 (Conv2D)           (None, 16, 16, 256)       196864    \n",
            "_________________________________________________________________\n",
            "batch_normalization_69 (Batc (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_80 (Activation)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_67 (Conv2D)           (None, 8, 8, 512)         393728    \n",
            "_________________________________________________________________\n",
            "batch_normalization_70 (Batc (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "activation_81 (Activation)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_68 (Conv2D)           (None, 8, 8, 512)         786944    \n",
            "_________________________________________________________________\n",
            "batch_normalization_71 (Batc (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "activation_82 (Activation)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_69 (Conv2D)           (None, 4, 4, 1024)        1573888   \n",
            "_________________________________________________________________\n",
            "batch_normalization_72 (Batc (None, 4, 4, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "activation_83 (Activation)   (None, 4, 4, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_70 (Conv2D)           (None, 4, 4, 1024)        3146752   \n",
            "_________________________________________________________________\n",
            "batch_normalization_73 (Batc (None, 4, 4, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "activation_84 (Activation)   (None, 4, 4, 1024)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 2, 2, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_71 (Conv2D)           (None, 2, 2, 2056)        6318088   \n",
            "_________________________________________________________________\n",
            "batch_normalization_74 (Batc (None, 2, 2, 2056)        8224      \n",
            "_________________________________________________________________\n",
            "activation_85 (Activation)   (None, 2, 2, 2056)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_72 (Conv2D)           (None, 2, 2, 2056)        12683464  \n",
            "_________________________________________________________________\n",
            "batch_normalization_75 (Batc (None, 2, 2, 2056)        8224      \n",
            "_________________________________________________________________\n",
            "activation_86 (Activation)   (None, 2, 2, 2056)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 2, 2, 2056)        0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 2, 2, 2056)        0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d_3 (Average (None, 1, 1, 2056)        0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 2056)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                20570     \n",
            "_________________________________________________________________\n",
            "activation_87 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,370,346\n",
            "Trainable params: 25,353,930\n",
            "Non-trainable params: 16,416\n",
            "_________________________________________________________________\n",
            "\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_73 (Conv2D)           (None, 32, 32, 128)       1280      \n",
            "_________________________________________________________________\n",
            "activation_88 (Activation)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_76 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_74 (Conv2D)           (None, 32, 32, 128)       49280     \n",
            "_________________________________________________________________\n",
            "activation_89 (Activation)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_77 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_75 (Conv2D)           (None, 16, 16, 256)       98560     \n",
            "_________________________________________________________________\n",
            "batch_normalization_78 (Batc (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_90 (Activation)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_76 (Conv2D)           (None, 16, 16, 256)       196864    \n",
            "_________________________________________________________________\n",
            "batch_normalization_79 (Batc (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_91 (Activation)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_77 (Conv2D)           (None, 16, 16, 512)       393728    \n",
            "_________________________________________________________________\n",
            "batch_normalization_80 (Batc (None, 16, 16, 512)       2048      \n",
            "_________________________________________________________________\n",
            "activation_92 (Activation)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_78 (Conv2D)           (None, 16, 16, 512)       786944    \n",
            "_________________________________________________________________\n",
            "batch_normalization_81 (Batc (None, 16, 16, 512)       2048      \n",
            "_________________________________________________________________\n",
            "activation_93 (Activation)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_79 (Conv2D)           (None, 16, 16, 1024)      1573888   \n",
            "_________________________________________________________________\n",
            "batch_normalization_82 (Batc (None, 16, 16, 1024)      4096      \n",
            "_________________________________________________________________\n",
            "activation_94 (Activation)   (None, 16, 16, 1024)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_80 (Conv2D)           (None, 16, 16, 1024)      3146752   \n",
            "_________________________________________________________________\n",
            "batch_normalization_83 (Batc (None, 16, 16, 1024)      4096      \n",
            "_________________________________________________________________\n",
            "activation_95 (Activation)   (None, 16, 16, 1024)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 8, 8, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_81 (Conv2D)           (None, 8, 8, 2056)        6318088   \n",
            "_________________________________________________________________\n",
            "batch_normalization_84 (Batc (None, 8, 8, 2056)        8224      \n",
            "_________________________________________________________________\n",
            "activation_96 (Activation)   (None, 8, 8, 2056)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_82 (Conv2D)           (None, 8, 8, 2056)        12683464  \n",
            "_________________________________________________________________\n",
            "batch_normalization_85 (Batc (None, 8, 8, 2056)        8224      \n",
            "_________________________________________________________________\n",
            "activation_97 (Activation)   (None, 8, 8, 2056)        0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d_4 (Average (None, 4, 4, 2056)        0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 32896)             0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                328970    \n",
            "_________________________________________________________________\n",
            "activation_98 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,609,626\n",
            "Trainable params: 25,593,722\n",
            "Non-trainable params: 15,904\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM3f-PcnR-YP",
        "colab_type": "text"
      },
      "source": [
        "# Executing the Model\n",
        "Now, the model built above will be executed with the training set. If there are more than one GPUs on the computer this file is being called in, then it will parallelize the model between the GPUs, else it will execute on the one GPU and CPU. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApLHVEugUVNu",
        "colab_type": "code",
        "outputId": "cf051963-d226-4b29-d24b-b20b5351e86f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# First, check the available amount of parallel GPUs\n",
        "print(tf.keras.__version__)\n",
        "# if '2.' in tf.keras.__version__:\n",
        "#   from keras import backend as K\n",
        "#   gpus = K.tensorflow_backend._get_available_gpus()\n",
        "#   print('Available GPUs on this device are: ' + str(gpus))\n",
        "\n",
        "#   isParallel = len(gpus) > 1\n",
        "# else:\n",
        "isParallel = False # toggle for testing purposes\n",
        "learning_rate = 0.1\n",
        "decay_rate = 20"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM1oiUtCsOQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now, to add a learning rate scheduler to see if there is an effect\n",
        "def schedule_lr(epoch):\n",
        "  return learning_rate * 0.5 ** (epoch // decay_rate)\n",
        "\n",
        "schedule_lr = tf.keras.callbacks.LearningRateScheduler(schedule_lr, verbose=1)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01wmaqL7QAe4",
        "colab_type": "code",
        "outputId": "4563a9b2-d683-435e-eb95-69f2df1832a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        }
      },
      "source": [
        "# Now, run the model.\n",
        "optimizer = tf.keras.optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9, \n",
        "                                    nesterov = True)\n",
        "# optimizer = tf.keras.optimizers.Adam(epsilon=1e-8)\n",
        "history = None\n",
        "\n",
        "if isParallel:\n",
        "  print('GPUs parallelized!')\n",
        "  multi_gpu_model = tf.keras.utils.multi_gpu_model(model1, 2)\n",
        "  history = multi_gpu_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", \n",
        "                                    metrics=['accuracy'])\n",
        "  multi_gpu_model.fit_generator(data_gen.flow(x_train, y_train, batch_size=BATCH_SIZE), \n",
        "                      steps_per_epoch=(x_train.shape[0] // BATCH_SIZE), epochs=EPOCHS,\n",
        "                      validation_data=(x_test, y_test), callbacks=[schedule_lr])\n",
        "else:\n",
        "  print('CPU Compilation')\n",
        "  \n",
        "  history = model1.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", \n",
        "                metrics=['accuracy'])\n",
        "  model1.fit_generator(data_gen.flow(x_train, y_train, batch_size=BATCH_SIZE), \n",
        "                      steps_per_epoch=(x_train.shape[0] // BATCH_SIZE), epochs=EPOCHS,\n",
        "                      validation_data=(x_test, y_test), callbacks=[schedule_lr])\n",
        "\n",
        "with open('model1.txt', 'w+') as file:\n",
        "  file.write(history)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU Compilation\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.1.\n",
            "Epoch 1/100\n",
            " 50/390 [==>...........................] - ETA: 1:17 - loss: 25.4855 - acc: 0.1052"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-824e7432b023>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m   model1.fit_generator(data_gen.flow(x_train, y_train, batch_size=BATCH_SIZE), \n\u001b[1;32m     20\u001b[0m                       \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                       validation_data=(x_test, y_test), callbacks=[schedule_lr])\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model1.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator, mode)\u001b[0m\n\u001b[1;32m    360\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAZRk0OGVYXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now, run the model.\n",
        "optimizer = tf.keras.optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9, nesterov = True)\n",
        "# optimizer = tf.keras.optimizers.Adam(epsilon=1e-8)\n",
        "history = None\n",
        "\n",
        "if isParallel:\n",
        "  print('GPUs parallelized!')\n",
        "  multi_gpu_model = tf.keras.utils.multi_gpu_model(model2, 2)\n",
        "  history = multi_gpu_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "  multi_gpu_model.fit_generator(data_gen.flow(x_train, y_train, batch_size=BATCH_SIZE), \n",
        "                      steps_per_epoch=(x_train.shape[0] // BATCH_SIZE), epochs=EPOCHS,\n",
        "                      validation_data=(x_test, y_test), callbacks=[schedule_lr])\n",
        "else:\n",
        "  print('CPU Compilation')\n",
        "  \n",
        "  history = model2.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", \n",
        "                metrics=['accuracy'])\n",
        "  model2.fit_generator(data_gen.flow(x_train, y_train, batch_size=BATCH_SIZE), \n",
        "                      steps_per_epoch=(x_train.shape[0] // BATCH_SIZE), epochs=EPOCHS,\n",
        "                      validation_data=(x_test, y_test), callbacks=[schedule_lr])\n",
        "\n",
        "with open('model2.txt', 'w+') as file:\n",
        "  file.write(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ7NSImrVaEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now, run the model.\n",
        "optimizer = tf.keras.optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9, nesterov = True)\n",
        "# optimizer = tf.keras.optimizers.Adam(epsilon=1e-8)\n",
        "history = None\n",
        "\n",
        "if isParallel:\n",
        "  print('GPUs parallelized!')\n",
        "  multi_gpu_model = tf.keras.utils.multi_gpu_model(model3, 2)\n",
        "  history = multi_gpu_model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "  multi_gpu_model.fit_generator(data_gen.flow(x_train, y_train, batch_size=BATCH_SIZE), \n",
        "                      steps_per_epoch=(x_train.shape[0] // BATCH_SIZE), epochs=EPOCHS,\n",
        "                      validation_data=(x_test, y_test), callbacks=[schedule_lr])\n",
        "else:\n",
        "  print('CPU Compilation')\n",
        "  \n",
        "  history = model3.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", \n",
        "                metrics=['accuracy'])\n",
        "  model3.fit_generator(data_gen.flow(x_train, y_train, batch_size=BATCH_SIZE), \n",
        "                      steps_per_epoch=(x_train.shape[0] // BATCH_SIZE), epochs=EPOCHS,\n",
        "                      validation_data=(x_test, y_test), callbacks=[schedule_lr])\n",
        "\n",
        "with open('model3.txt', 'w+') as file:\n",
        "  file.write(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2nnRekKgFrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}